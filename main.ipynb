{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554194bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openvino\\runtime\\__init__.py:10: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = str(os.cpu_count() // 2)\n",
    "#os.environ[\"GOMP_CPU_AFFINITY\"] = \"granularity=core,compact\"\n",
    "from Scripts.model import *\n",
    "from Scripts.asymmetric_model import *\n",
    "from Scripts.loss import *\n",
    "from Scripts.results_manager import *\n",
    "from Scripts.plots import *\n",
    "from Scripts.dataset import *\n",
    "from Scripts.trainer import *\n",
    "from Scripts.inference import *\n",
    "from Scripts.Onnx_Class import *\n",
    "from Scripts.lr_finder import *\n",
    "from Scripts.generate_configs import *\n",
    "#from Scripts.asymmetric_model import *\n",
    "from Scripts.generate_asymmetric_configs import *\n",
    "from Scripts.excecute import *\n",
    "from Scripts.quantize_new import *\n",
    "from Scripts.upload_summaries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"Asymmetric_Configs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_selected_class(config_path, 'grid')\n",
    "# metrics_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e587851",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_all_classes(config_path)\n",
    "metrics_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_run_folder = \"Training_Runs\"\n",
    "inference_output_dir = \"Inference_Runs\"\n",
    "\n",
    "inference_model(training_run_folder, inference_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c54cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Unveränderter Teil: Pfade sammeln ---\n",
    "config_paths_all = glob.glob(os.path.join(\n",
    "    \"Training_Runs\", \"**\", \"*.yaml\"), recursive=True)\n",
    "summary_metrics_paths_all = glob.glob(os.path.join(\n",
    "    \"Training_Runs\", \"**\", \"summary_metrics.json\"), recursive=True)\n",
    "best_student_weight_paths_all = glob.glob(os.path.join(\n",
    "    \"Training_Runs\", \"**\", \"*best_student.pth\"), recursive=True)\n",
    "\n",
    "config_paths = [\n",
    "    p for p in config_paths_all if not any(part.startswith('tf_efficient') for part in p.split(os.sep))]\n",
    "summary_metrics_paths = [\n",
    "    p for p in summary_metrics_paths_all if not any(part.startswith('tf_efficient') for part in p.split(os.sep))]\n",
    "best_student_weight_paths = [\n",
    "    p for p in best_student_weight_paths_all if not any(part.startswith('tf_efficient') for part in p.split(os.sep))]\n",
    "\n",
    "\n",
    "for configs, summary_metrics, best_student_weights in zip(config_paths, summary_metrics_paths, best_student_weight_paths):\n",
    "    config = load_config(configs)\n",
    "    summary_metric = load_json(summary_metrics)\n",
    "    quantize_model(\n",
    "        best_student_weights,\n",
    "        config,\n",
    "        summary_metric\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_output_dir = 'quantized_inference_results'\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "# Finde alle quantisierten Modelle im Ordner\n",
    "quantized_weight_paths = glob.glob(os.path.join(\n",
    "    \"quantized_models\", \"**\", \"quantized_model.pth\"), recursive=True)\n",
    "\n",
    "print(\n",
    "    f\"Führe Inferenz für {len(quantized_weight_paths)} quantisierte Modelle aus...\")\n",
    "\n",
    "for weight_path in quantized_weight_paths:\n",
    "    dirpath = os.path.dirname(weight_path)\n",
    "    print(f\"\\n--- Verarbeite Modell in: {dirpath} ---\")\n",
    "\n",
    "    # Finde die zugehörigen Konfigurationsdateien\n",
    "    yaml_filename = None\n",
    "    for file in os.listdir(dirpath):\n",
    "        if file.endswith('.yaml'):\n",
    "            yaml_filename = file\n",
    "            break\n",
    "\n",
    "    if yaml_filename is None:\n",
    "        print(\n",
    "            f\"Warnung: Keine YAML-Konfigurationsdatei in {dirpath} gefunden. Überspringe.\")\n",
    "        continue\n",
    "\n",
    "    json_path = os.path.join(dirpath, \"summary_metric.json\")\n",
    "    yaml_path = os.path.join(dirpath, yaml_filename)\n",
    "\n",
    "    if not os.path.exists(json_path):\n",
    "        print(\n",
    "            f\"Warnung: Keine summary_metric.json in {dirpath} gefunden. Überspringe.\")\n",
    "        continue\n",
    "\n",
    "    # Lade Konfigurationen\n",
    "    config_data = load_config(yaml_path)\n",
    "    summary_data = load_json(json_path)\n",
    "    training_id = summary_data.get(\n",
    "        'training_id', 'quantized_run')  # Nutze Fallback\n",
    "\n",
    "    # --- WICHTIGER TEIL: Lade das quantisierte Modell korrekt ---\n",
    "\n",
    "    # 1. Erstelle das leere STFPM-Modellgerüst\n",
    "    inference_model = STFPM(\n",
    "        architecture=config_data['model']['architecture'],\n",
    "        layers=config_data['model']['layers']\n",
    "    )\n",
    "    inference_model.eval()\n",
    "    student_model_to_quantize = inference_model.student_model\n",
    "    student_model_to_quantize.eval()\n",
    "\n",
    "    # 2. Bereite das student_model mit der exakt gleichen FX-Konfiguration vor\n",
    "    qconfig_mapping = get_default_qconfig_mapping(\"fbgemm\")\n",
    "    example_inputs = (torch.randn(1, 3, 256, 256),)\n",
    "    prepared_model = prepare_fx(\n",
    "        student_model_to_quantize, qconfig_mapping, example_inputs)\n",
    "    quantized_student_model = convert_fx(prepared_model)\n",
    "\n",
    "    # 3. Lade jetzt die gespeicherten, quantisierten Gewichte\n",
    "    quantized_student_model.load_state_dict(\n",
    "        torch.load(weight_path, map_location=cpu_device))\n",
    "    quantized_student_model.eval()\n",
    "    print(\"Quantisierte Gewichte erfolgreich geladen.\")\n",
    "\n",
    "    # 4. Setze das quantisierte student_model in das STFPM-Gesamtmodell ein\n",
    "    inference_model.student_model = quantized_student_model\n",
    "    inference_model.to(cpu_device)\n",
    "\n",
    "    # --- Ab hier läuft die Inferenz wie gewohnt ---\n",
    "\n",
    "    # Lade die Testdaten\n",
    "    try:\n",
    "        test_set = MVTecDataset(\n",
    "            img_size=config_data['dataset']['img_size'],\n",
    "            base_path=config_data['dataset']['base_path'],\n",
    "            cls=config_data['dataset']['class'],\n",
    "            mode='test',\n",
    "            download_if_missing=False\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_set,\n",
    "            batch_size=config_data['dataloader']['batch_size'],\n",
    "            shuffle=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Laden des Test-Datensatzes für {yaml_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Führe die Inferenz aus\n",
    "    infer = Inference(\n",
    "        model=inference_model,\n",
    "        test_loader=test_loader,\n",
    "        config=config_data,\n",
    "        output_dir=inference_output_dir,\n",
    "        path_to_student_weight=None,\n",
    "        trainings_id=training_id,\n",
    "        inferenz=True\n",
    "    )\n",
    "\n",
    "    print(f\"Starte Inferenz für Konfiguration: {yaml_path}...\")\n",
    "    auroc_score, total_inference_time = infer.evaluate_loaded_model()\n",
    "    infer.create_inference_summary(\n",
    "        summary_data, auroc_score, total_inference_time)\n",
    "    print(\n",
    "        f\"Inferenz abgeschlossen. AUROC: {auroc_score:.4f}, Zeit: {total_inference_time:.4f}s.\")\n",
    "\n",
    "    infer.generate_heatmaps_from_saved_maps()\n",
    "\n",
    "print(\"\\n--- Alle Inferenzläufe abgeschlossen. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b66448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 1. ONNX-Modell laden\n",
    "onnx_model_path = r\"onnx_models\\STFPM_resnet18.onnx\"\n",
    "sess = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "image_path = glob.glob(os.path.join(\n",
    "    r'Images\\bottle\\test\\broken_large', '*.png'))\n",
    "for path in image_path:\n",
    "\n",
    "    # 2. Ein Bild für die Inferenz vorbereiten\n",
    "    # image_path = r\"Images\\grid\\test\\bent\\003.png\"\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "    # Resize the image to the expected input size\n",
    "    img_size = 256\n",
    "    image = image.resize((img_size, img_size))\n",
    "\n",
    "    input_data = np.array(image, dtype=np.uint8)\n",
    "    input_data = np.expand_dims(input_data, axis=0)  # Add batch dimension\n",
    "\n",
    "    # 3. Inferenz durchführen\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    outputs = sess.run(None, {input_name: input_data})\n",
    "\n",
    "    # 4. Ergebnisse auswerten\n",
    "    anomaly_map = outputs[0]\n",
    "    anomaly_score = outputs[1]\n",
    "\n",
    "    print(f\"Anomalie-Score für das Bild: {anomaly_score[0]}\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # 2. Originalbild anzeigen\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"Originalbild\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # 3. Heatmap über das Originalbild legen\n",
    "    axes[1].imshow(image)\n",
    "    heatmap = axes[1].imshow(np.squeeze(anomaly_map), cmap='jet', alpha=0.5)\n",
    "    axes[1].set_title(\"Anomalie-Heatmap\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # 4. Farbbalken für die Heatmap hinzufügen\n",
    "    fig.colorbar(heatmap, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    # 5. Plot anzeigen oder speichern\n",
    "    plt.suptitle(\"Vergleich: Originalbild vs. Anomalie-Heatmap\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b5c651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Scripts\\streamlit.EXE\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "print(shutil.which(\"streamlit\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
