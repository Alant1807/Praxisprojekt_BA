{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554194bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openvino\\runtime\\__init__.py:10: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = str(os.cpu_count() // 2)\n",
    "#os.environ[\"GOMP_CPU_AFFINITY\"] = \"granularity=core,compact\"\n",
    "from Scripts.model import *\n",
    "from Scripts.asymmetric_model import *\n",
    "from Scripts.loss import *\n",
    "from Scripts.results_manager import *\n",
    "from Scripts.plots import *\n",
    "from Scripts.dataset import *\n",
    "from Scripts.trainer import *\n",
    "from Scripts.inference import *\n",
    "from Scripts.Onnx_Class import *\n",
    "from Scripts.lr_finder import *\n",
    "from Scripts.generate_configs import *\n",
    "#from Scripts.asymmetric_model import *\n",
    "from Scripts.generate_asymmetric_configs import *\n",
    "from Scripts.excecute import *\n",
    "#from Scripts.quantize import *\n",
    "from Scripts.quantize_new import *\n",
    "from Scripts.upload_summaries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"Asymmetric_Configs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_selected_class(config_path, 'grid')\n",
    "# metrics_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e587851",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_all_classes(config_path)\n",
    "metrics_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_run_folder = \"Training_Runs\"\n",
    "inference_output_dir = \"Inference_Runs\"\n",
    "\n",
    "inference_model(training_run_folder, inference_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c54cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths = glob.glob(os.path.join(\n",
    "    \"Training_Runs\", \"**\", \"*.yaml\"), recursive=True)\n",
    "summary_metrics_paths = glob.glob(os.path.join(\n",
    "    \"Training_Runs\", \"**\", \"summary_metrics.json\"), recursive=True)\n",
    "best_student_weight_paths = glob.glob(os.path.join(\n",
    "    \"Training_Runs\", \"**\", \"*best_student.pth\"), recursive=True)\n",
    "for configs, summary_metrics, best_student_weights in zip(config_paths, summary_metrics_paths, best_student_weight_paths):\n",
    "    config = load_config(configs)\n",
    "    summary_metric = load_json(summary_metrics)\n",
    "    quantize_model(\n",
    "        best_student_weights,\n",
    "        config,\n",
    "        summary_metric\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ee4666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Führe Inferenz für 5 quantisierte Modelle aus...\n",
      "\n",
      "--- Verarbeite Modell in: quantized_models\\mobilenetv3_large_100\\f07b3762-1522-4748-bb8c-60cfbcfa621b ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_27532\\124296653.py:55: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  prepared_model = prepare_fx(\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_27532\\124296653.py:57: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized_student_model = convert_fx(prepared_model)\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:1343: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_utils.py:465: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantisierte Gewichte erfolgreich geladen.\n",
      "Starte Inferenz für Konfiguration: quantized_models\\mobilenetv3_large_100\\f07b3762-1522-4748-bb8c-60cfbcfa621b\\STFPM_Config_mobilenetv3_large_100.yaml...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference summary saved to quantized_inference_results\\MVTecAD_bottle\\mobilenetv3_large_100\\f07b3762-1522-4748-bb8c-60cfbcfa621b\\inference_summary.json\n",
      "Inferenz abgeschlossen. AUROC: 0.9865, Zeit: 1.2477s.\n",
      "\n",
      "Starte Heatmap-Generierung aus gespeicherten Karten für: quantized_inference_results\\MVTecAD_bottle\\mobilenetv3_large_100\\f07b3762-1522-4748-bb8c-60cfbcfa621b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Erstelle Heatmaps: 100%|██████████| 83/83 [00:19<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap-Generierung abgeschlossen. Ergebnisse in 'quantized_inference_results\\MVTecAD_bottle\\mobilenetv3_large_100\\f07b3762-1522-4748-bb8c-60cfbcfa621b\\plots' gespeichert.\n",
      "\n",
      "--- Verarbeite Modell in: quantized_models\\mobilenetv4_conv_large\\4a432118-97f9-4fd4-9f1d-29e114a5888f ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_27532\\124296653.py:55: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  prepared_model = prepare_fx(\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_27532\\124296653.py:57: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized_student_model = convert_fx(prepared_model)\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:1343: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantisierte Gewichte erfolgreich geladen.\n",
      "Starte Inferenz für Konfiguration: quantized_models\\mobilenetv4_conv_large\\4a432118-97f9-4fd4-9f1d-29e114a5888f\\STFPM_Config_mobilenetv4_conv_large.yaml...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference summary saved to quantized_inference_results\\MVTecAD_bottle\\mobilenetv4_conv_large\\4a432118-97f9-4fd4-9f1d-29e114a5888f\\inference_summary.json\n",
      "Inferenz abgeschlossen. AUROC: 0.9849, Zeit: 3.1128s.\n",
      "\n",
      "Starte Heatmap-Generierung aus gespeicherten Karten für: quantized_inference_results\\MVTecAD_bottle\\mobilenetv4_conv_large\\4a432118-97f9-4fd4-9f1d-29e114a5888f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Erstelle Heatmaps: 100%|██████████| 83/83 [00:20<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap-Generierung abgeschlossen. Ergebnisse in 'quantized_inference_results\\MVTecAD_bottle\\mobilenetv4_conv_large\\4a432118-97f9-4fd4-9f1d-29e114a5888f\\plots' gespeichert.\n",
      "\n",
      "--- Verarbeite Modell in: quantized_models\\mobilenetv4_conv_medium\\c68cc551-8f66-45d5-adf3-45cfb70107b0 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_27532\\124296653.py:55: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  prepared_model = prepare_fx(\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_27532\\124296653.py:57: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized_student_model = convert_fx(prepared_model)\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:1343: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantisierte Gewichte erfolgreich geladen.\n",
      "Starte Inferenz für Konfiguration: quantized_models\\mobilenetv4_conv_medium\\c68cc551-8f66-45d5-adf3-45cfb70107b0\\STFPM_Config_mobilenetv4_conv_medium.yaml...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference summary saved to quantized_inference_results\\MVTecAD_bottle\\mobilenetv4_conv_medium\\c68cc551-8f66-45d5-adf3-45cfb70107b0\\inference_summary.json\n",
      "Inferenz abgeschlossen. AUROC: 0.9817, Zeit: 1.6326s.\n",
      "\n",
      "Starte Heatmap-Generierung aus gespeicherten Karten für: quantized_inference_results\\MVTecAD_bottle\\mobilenetv4_conv_medium\\c68cc551-8f66-45d5-adf3-45cfb70107b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Erstelle Heatmaps: 100%|██████████| 83/83 [00:19<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap-Generierung abgeschlossen. Ergebnisse in 'quantized_inference_results\\MVTecAD_bottle\\mobilenetv4_conv_medium\\c68cc551-8f66-45d5-adf3-45cfb70107b0\\plots' gespeichert.\n",
      "\n",
      "--- Verarbeite Modell in: quantized_models\\mobilenetv4_conv_small\\e54554d9-fb69-4a31-9d46-8edd82d7450a ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.weight, norm_head.bias, norm_head.num_batches_tracked, norm_head.running_mean, norm_head.running_var, norm_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_27532\\124296653.py:55: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  prepared_model = prepare_fx(\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_27532\\124296653.py:57: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized_student_model = convert_fx(prepared_model)\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:1343: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantisierte Gewichte erfolgreich geladen.\n",
      "Starte Inferenz für Konfiguration: quantized_models\\mobilenetv4_conv_small\\e54554d9-fb69-4a31-9d46-8edd82d7450a\\STFPM_Config_mobilenetv4_conv_small.yaml...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference summary saved to quantized_inference_results\\MVTecAD_bottle\\mobilenetv4_conv_small\\e54554d9-fb69-4a31-9d46-8edd82d7450a\\inference_summary.json\n",
      "Inferenz abgeschlossen. AUROC: 0.9437, Zeit: 0.4808s.\n",
      "\n",
      "Starte Heatmap-Generierung aus gespeicherten Karten für: quantized_inference_results\\MVTecAD_bottle\\mobilenetv4_conv_small\\e54554d9-fb69-4a31-9d46-8edd82d7450a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Erstelle Heatmaps: 100%|██████████| 83/83 [00:19<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap-Generierung abgeschlossen. Ergebnisse in 'quantized_inference_results\\MVTecAD_bottle\\mobilenetv4_conv_small\\e54554d9-fb69-4a31-9d46-8edd82d7450a\\plots' gespeichert.\n",
      "\n",
      "--- Verarbeite Modell in: quantized_models\\resnet18\\22a1ec46-6ca8-42ec-8889-6a2956edf095 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_27532\\124296653.py:55: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  prepared_model = prepare_fx(\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_27532\\124296653.py:57: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized_student_model = convert_fx(prepared_model)\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:1343: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantisierte Gewichte erfolgreich geladen.\n",
      "Starte Inferenz für Konfiguration: quantized_models\\resnet18\\22a1ec46-6ca8-42ec-8889-6a2956edf095\\STFPM_Config_resnet18.yaml...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference summary saved to quantized_inference_results\\MVTecAD_bottle\\resnet18\\22a1ec46-6ca8-42ec-8889-6a2956edf095\\inference_summary.json\n",
      "Inferenz abgeschlossen. AUROC: 1.0000, Zeit: 1.4990s.\n",
      "\n",
      "Starte Heatmap-Generierung aus gespeicherten Karten für: quantized_inference_results\\MVTecAD_bottle\\resnet18\\22a1ec46-6ca8-42ec-8889-6a2956edf095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Erstelle Heatmaps: 100%|██████████| 83/83 [00:19<00:00,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap-Generierung abgeschlossen. Ergebnisse in 'quantized_inference_results\\MVTecAD_bottle\\resnet18\\22a1ec46-6ca8-42ec-8889-6a2956edf095\\plots' gespeichert.\n",
      "\n",
      "--- Alle Inferenzläufe abgeschlossen. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inference_output_dir = 'quantized_inference_results'\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "# Finde alle quantisierten Modelle im Ordner\n",
    "quantized_weight_paths = glob.glob(os.path.join(\n",
    "    \"quantized_models\", \"**\", \"quantized_model.pth\"), recursive=True)\n",
    "\n",
    "print(\n",
    "    f\"Führe Inferenz für {len(quantized_weight_paths)} quantisierte Modelle aus...\")\n",
    "\n",
    "for weight_path in quantized_weight_paths:\n",
    "    dirpath = os.path.dirname(weight_path)\n",
    "    print(f\"\\n--- Verarbeite Modell in: {dirpath} ---\")\n",
    "\n",
    "    # Finde die zugehörigen Konfigurationsdateien\n",
    "    yaml_filename = None\n",
    "    for file in os.listdir(dirpath):\n",
    "        if file.endswith('.yaml'):\n",
    "            yaml_filename = file\n",
    "            break\n",
    "\n",
    "    if yaml_filename is None:\n",
    "        print(\n",
    "            f\"Warnung: Keine YAML-Konfigurationsdatei in {dirpath} gefunden. Überspringe.\")\n",
    "        continue\n",
    "\n",
    "    json_path = os.path.join(dirpath, \"summary_metric.json\")\n",
    "    yaml_path = os.path.join(dirpath, yaml_filename)\n",
    "\n",
    "    if not os.path.exists(json_path):\n",
    "        print(\n",
    "            f\"Warnung: Keine summary_metric.json in {dirpath} gefunden. Überspringe.\")\n",
    "        continue\n",
    "\n",
    "    # Lade Konfigurationen\n",
    "    config_data = load_config(yaml_path)\n",
    "    summary_data = load_json(json_path)\n",
    "    training_id = summary_data.get(\n",
    "        'training_id', 'quantized_run')  # Nutze Fallback\n",
    "\n",
    "    # --- WICHTIGER TEIL: Lade das quantisierte Modell korrekt ---\n",
    "\n",
    "    # 1. Erstelle das leere STFPM-Modellgerüst\n",
    "    inference_model = STFPM(\n",
    "        architecture=config_data['model']['architecture'],\n",
    "        layers=config_data['model']['layers']\n",
    "    )\n",
    "    inference_model.eval()\n",
    "    student_model_to_quantize = inference_model.student_model\n",
    "    student_model_to_quantize.eval()\n",
    "\n",
    "    # 2. Bereite das student_model mit der exakt gleichen FX-Konfiguration vor\n",
    "    qconfig_mapping = get_default_qconfig_mapping(\"fbgemm\")\n",
    "    example_inputs = (torch.randn(1, 3, 256, 256),)\n",
    "    prepared_model = prepare_fx(\n",
    "        student_model_to_quantize, qconfig_mapping, example_inputs)\n",
    "    quantized_student_model = convert_fx(prepared_model)\n",
    "\n",
    "    # 3. Lade jetzt die gespeicherten, quantisierten Gewichte\n",
    "    quantized_student_model.load_state_dict(\n",
    "        torch.load(weight_path, map_location=cpu_device))\n",
    "    quantized_student_model.eval()\n",
    "    print(\"Quantisierte Gewichte erfolgreich geladen.\")\n",
    "\n",
    "    # 4. Setze das quantisierte student_model in das STFPM-Gesamtmodell ein\n",
    "    inference_model.student_model = quantized_student_model\n",
    "    inference_model.to(cpu_device)\n",
    "\n",
    "    # --- Ab hier läuft die Inferenz wie gewohnt ---\n",
    "\n",
    "    # Lade die Testdaten\n",
    "    try:\n",
    "        test_set = MVTecDataset(\n",
    "            img_size=config_data['dataset']['img_size'],\n",
    "            base_path=config_data['dataset']['base_path'],\n",
    "            cls=config_data['dataset']['class'],\n",
    "            mode='test',\n",
    "            download_if_missing=False\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_set,\n",
    "            batch_size=config_data['dataloader']['batch_size'],\n",
    "            shuffle=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Laden des Test-Datensatzes für {yaml_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Führe die Inferenz aus\n",
    "    infer = Inference(\n",
    "        model=inference_model,\n",
    "        test_loader=test_loader,\n",
    "        config=config_data,\n",
    "        output_dir=inference_output_dir,\n",
    "        path_to_student_weight=None,\n",
    "        trainings_id=training_id,\n",
    "        inferenz=True\n",
    "    )\n",
    "\n",
    "    print(f\"Starte Inferenz für Konfiguration: {yaml_path}...\")\n",
    "    auroc_score, total_inference_time = infer.evaluate_loaded_model()\n",
    "    infer.create_inference_summary(\n",
    "        summary_data, auroc_score, total_inference_time)\n",
    "    print(\n",
    "        f\"Inferenz abgeschlossen. AUROC: {auroc_score:.4f}, Zeit: {total_inference_time:.4f}s.\")\n",
    "\n",
    "    infer.generate_heatmaps_from_saved_maps()\n",
    "\n",
    "print(\"\\n--- Alle Inferenzläufe abgeschlossen. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e6e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade Konfiguration und Metriken\n",
    "config = load_config(\n",
    "    r'Training_Runs\\MVTecAD_grid\\resnet18\\2830be19-bea8-41f8-a1e8-1a6ef49b8cbc\\STFPM_Config_resnet18.yaml')\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "summary_metrics = load_json(\n",
    "    r'Training_Runs\\MVTecAD_grid\\resnet18\\2830be19-bea8-41f8-a1e8-1a6ef49b8cbc\\summary_metrics.json')\n",
    "\n",
    "# 1. Quantisiere NUR das student_model mit deiner neuen FX-Funktion\n",
    "quantized_student_model = quantize_model(\n",
    "    r'Training_Runs\\MVTecAD_grid\\resnet18\\2830be19-bea8-41f8-a1e8-1a6ef49b8cbc\\weights\\resnet18_grid_2830be19-bea8-41f8-a1e8-1a6ef49b8cbc_best_student.pth',\n",
    "    config\n",
    ")\n",
    "\n",
    "# 2. Erstelle ein neues, vollständiges STFPM-Modell für die Inferenz\n",
    "inference_model = STFPM(\n",
    "    architecture=config['model']['architecture'],\n",
    "    layers=config['model']['layers']\n",
    ")\n",
    "\n",
    "# 3. Ersetze das untrainierte student_model durch deine quantisierte Version\n",
    "inference_model.student_model = quantized_student_model\n",
    "inference_model.to(cpu_device).eval()\n",
    "\n",
    "\n",
    "# Lade die Testdaten\n",
    "test_set = MVTecDataset(\n",
    "    img_size=config['dataset']['img_size'],\n",
    "    base_path=config['dataset']['base_path'],\n",
    "    cls=config['dataset']['class'],\n",
    "    mode='test',\n",
    "    download_if_missing=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=config['dataloader']['batch_size'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 4. Übergebe das vollständige, zusammengesetzte Modell an die Inference-Klasse\n",
    "infer = Inference(\n",
    "    model=inference_model,  # <--- Hier wird das korrekte Modell übergeben\n",
    "    test_loader=test_loader,\n",
    "    config=config,\n",
    "    path_to_student_weight=None,  # Gewichte sind schon geladen\n",
    "    trainings_id=summary_metrics.get('training_id'),\n",
    "    inferenz=True\n",
    ")\n",
    "\n",
    "# 5. Führe die Inferenz aus\n",
    "auroc, inf_time = infer.evaluate_per_epoch()\n",
    "print(f\"AUROC: {auroc}, Inference Time: {inf_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b66448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 1. ONNX-Modell laden\n",
    "onnx_model_path = r\"onnx_models\\STFPM_resnet18.onnx\"\n",
    "sess = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "image_path = glob.glob(os.path.join(\n",
    "    r'Images\\bottle\\test\\broken_large', '*.png'))\n",
    "for path in image_path:\n",
    "\n",
    "    # 2. Ein Bild für die Inferenz vorbereiten\n",
    "    # image_path = r\"Images\\grid\\test\\bent\\003.png\"\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "    # Resize the image to the expected input size\n",
    "    img_size = 256\n",
    "    image = image.resize((img_size, img_size))\n",
    "\n",
    "    input_data = np.array(image, dtype=np.uint8)\n",
    "    input_data = np.expand_dims(input_data, axis=0)  # Add batch dimension\n",
    "\n",
    "    # 3. Inferenz durchführen\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    outputs = sess.run(None, {input_name: input_data})\n",
    "\n",
    "    # 4. Ergebnisse auswerten\n",
    "    anomaly_map = outputs[0]\n",
    "    anomaly_score = outputs[1]\n",
    "\n",
    "    print(f\"Anomalie-Score für das Bild: {anomaly_score[0]}\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # 2. Originalbild anzeigen\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"Originalbild\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # 3. Heatmap über das Originalbild legen\n",
    "    axes[1].imshow(image)\n",
    "    heatmap = axes[1].imshow(np.squeeze(anomaly_map), cmap='jet', alpha=0.5)\n",
    "    axes[1].set_title(\"Anomalie-Heatmap\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # 4. Farbbalken für die Heatmap hinzufügen\n",
    "    fig.colorbar(heatmap, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    # 5. Plot anzeigen oder speichern\n",
    "    plt.suptitle(\"Vergleich: Originalbild vs. Anomalie-Heatmap\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
