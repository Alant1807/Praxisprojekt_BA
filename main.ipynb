{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554194bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = str(os.cpu_count() // 2)\n",
    "#os.environ[\"GOMP_CPU_AFFINITY\"] = \"granularity=core,compact\"\n",
    "from Scripts.model2 import *\n",
    "from Scripts.loss import *\n",
    "from Scripts.results_manager import *\n",
    "from Scripts.plots import *\n",
    "from Scripts.dataset import *\n",
    "from Scripts.trainer import *\n",
    "from Scripts.inference import *\n",
    "from Scripts.Onnx_Class import *\n",
    "from Scripts.lr_finder import *\n",
    "from Scripts.generate_configs import *\n",
    "from Scripts.excecute import *\n",
    "from Scripts.upload_summaries import *\n",
    "from Scripts.quantize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"Configs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_selected_class(config_path, 'grid')\n",
    "# metrics_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e587851",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_all_classes(config_path)\n",
    "metrics_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_run_folder = \"Training_Runs\"\n",
    "inference_output_dir = \"Inference_Runs\"\n",
    "\n",
    "inference_model(training_run_folder, inference_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c54cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths_all = glob.glob(os.path.join(\n",
    "    \"Training_Runs\", \"**\", \"*.yaml\"), recursive=True)\n",
    "summary_metrics_paths_all = glob.glob(os.path.join(\n",
    "    \"Training_Runs\", \"**\", \"summary_metrics.json\"), recursive=True)\n",
    "best_student_weight_paths_all = glob.glob(os.path.join(\n",
    "    \"Training_Runs\", \"**\", \"*best_student.pth\"), recursive=True)\n",
    "\n",
    "for configs, summary_metrics, best_student_weights in zip(config_paths_all, summary_metrics_paths_all, best_student_weight_paths_all):\n",
    "    config = load_config(configs)\n",
    "    summary_metric = load_json(summary_metrics)\n",
    "    quantize_model(\n",
    "        best_student_weights,\n",
    "        config,\n",
    "        summary_metric\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef59b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_output_dir = 'quantized_inference_results'\n",
    "device = torch.device('cpu')\n",
    "\n",
    "quantized_weights_paths = glob.glob(os.path.join(\n",
    "    'quantized_models', '**', 'quantized_model.pth'), recursive=True)\n",
    "\n",
    "print(\n",
    "    f\"Führe Inferenz für {len(quantized_weights_paths)} quantisierte Modelle aus...\")\n",
    "\n",
    "for weight_path in quantized_weights_paths:\n",
    "    dir_path = os.path.dirname(weight_path)\n",
    "    model_name = Path(weight_path).parent.parent.name\n",
    "    print(f\"Modell aus {model_name} wird verwendet...\")\n",
    "\n",
    "    yaml_filename = None\n",
    "    for file in os.listdir(dir_path):\n",
    "        if file.endswith('.yaml'):\n",
    "            yaml_filename = file\n",
    "            break\n",
    "\n",
    "    if yaml_filename is None:\n",
    "        print(\n",
    "            f\"Keine YAML-Konfigurationsdatei im Verzeichnis {dir_path} gefunden.\")\n",
    "        continue\n",
    "\n",
    "    json_path = os.path.join(dir_path, 'summary_metric.json')\n",
    "    yaml_path = os.path.join(dir_path, yaml_filename)\n",
    "\n",
    "    if not os.path.exists(json_path):\n",
    "        print(\n",
    "            f\"Keine JSON-Zusammenfassungsdatei im Verzeichnis {dir_path} gefunden.\")\n",
    "        continue\n",
    "\n",
    "    config = load_config(yaml_path)\n",
    "    summary_data = load_json(json_path)\n",
    "    training_id = summary_data.get('training_id', 'quantized_run')\n",
    "\n",
    "    quantized_student = FeatureExtractor(\n",
    "        backbone=config['model']['architecture'],\n",
    "        pretrained=False,\n",
    "        layers=config['model']['layers'],\n",
    "        quantize=True,\n",
    "        requires_grad=True\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b66448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import time  # Hinzugefügt: Modul für die Zeitmessung\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. ONNX-Modell laden\n",
    "onnx_model_path = r\"onnx_models\\STFPM_bottle_mobilenetv4_conv_large.onnx\"\n",
    "sess = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "image_path = glob.glob(os.path.join(\n",
    "    r'Images\\bottle\\test\\broken_large', '*.png'))\n",
    "for path in image_path:\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "    img_size = 256\n",
    "    image = image.resize((img_size, img_size))\n",
    "\n",
    "    input_data = np.array(image, dtype=np.uint8)\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    outputs = sess.run(None, {input_name: input_data})\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    inference_time = end_time - start_time\n",
    "\n",
    "    anomaly_map = outputs[0]\n",
    "    anomaly_score = outputs[1]\n",
    "\n",
    "    print(f\"Anomalie-Score für das Bild: {anomaly_score[0]}\")\n",
    "    print(f\"Inferenzzeit: {inference_time:.4f} Sekunden\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # 2. Originalbild anzeigen\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"Originalbild\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # 3. Heatmap über das Originalbild legen\n",
    "    axes[1].imshow(image)\n",
    "    heatmap = axes[1].imshow(np.squeeze(anomaly_map), cmap='jet', alpha=0.5)\n",
    "    axes[1].set_title(\"Anomalie-Heatmap\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # 4. Farbbalken für die Heatmap hinzufügen\n",
    "    fig.colorbar(heatmap, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    # 5. Plot anzeigen oder speichern\n",
    "    plt.suptitle(\"Vergleich: Originalbild vs. Anomalie-Heatmap\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
