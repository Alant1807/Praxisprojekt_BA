{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554194bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openvino\\runtime\\__init__.py:10: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = str(os.cpu_count() // 2)\n",
    "#os.environ[\"GOMP_CPU_AFFINITY\"] = \"granularity=core,compact\"\n",
    "from Scripts.model2 import *\n",
    "from Scripts.model import *\n",
    "from Scripts.loss import *\n",
    "from Scripts.results_manager import *\n",
    "from Scripts.plots import *\n",
    "from Scripts.dataset import *\n",
    "from Scripts.trainer import *\n",
    "from Scripts.inference import *\n",
    "from Scripts.Onnx_Class import *\n",
    "from Scripts.lr_finder import *\n",
    "from Scripts.generate_configs import *\n",
    "from Scripts.excecute import *\n",
    "from Scripts.upload_summaries import *\n",
    "from Scripts.quantize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581e96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"Configs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_selected_class(config_path, 'grid')\n",
    "# metrics_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e587851",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_all_classes(config_path)\n",
    "metrics_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa98974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Inferenz für Konfiguration: Training_Runs\\MVTecAD_grid\\resnet18\\7804c936-9a41-467a-8dfc-e31f5c13998b\\STFPM_Config_resnet18.yaml...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PyTorch Profiler-Analyse ---\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  anomaly_map_inference         2.36%      63.964ms        57.07%        1.545s     772.452ms             2  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        41.64%        1.127s        42.68%        1.155s     385.167ms             3  \n",
      "                                           aten::conv2d         0.02%     409.900us        42.14%        1.141s      14.627ms            78  \n",
      "                                      aten::convolution         0.02%     562.000us        42.13%        1.140s      14.622ms            78  \n",
      "                                     aten::_convolution         0.03%     774.000us        42.11%        1.140s      14.614ms            78  \n",
      "                               aten::mkldnn_convolution        41.99%        1.137s        42.08%        1.139s      14.604ms            78  \n",
      "                                       aten::batch_norm         0.02%     477.900us         3.54%      95.810ms       1.228ms            78  \n",
      "                           aten::_batch_norm_impl_index         0.03%     783.000us         3.52%      95.332ms       1.222ms            78  \n",
      "                                aten::native_batch_norm         3.42%      92.694ms         3.49%      94.347ms       1.210ms            78  \n",
      "                                             aten::relu         0.02%     504.900us         3.30%      89.358ms       1.354ms            66  \n",
      "                                        aten::clamp_min         3.30%      89.265ms         3.30%      89.265ms       1.089ms            82  \n",
      "                                              aten::add         1.28%      34.522ms         1.28%      34.522ms       1.079ms            32  \n",
      "                              aten::upsample_bilinear2d         1.01%      27.222ms         1.01%      27.288ms       3.411ms             8  \n",
      "                                              aten::div         0.87%      23.481ms         0.89%      24.098ms     256.357us            94  \n",
      "                                       aten::max_pool2d         0.00%      33.300us         0.86%      23.411ms      11.706ms             2  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.707s\n",
      "\n",
      "Inference summary saved to Inference_Runs\\MVTecAD_grid\\resnet18\\7804c936-9a41-467a-8dfc-e31f5c13998b\\inference_summary.json\n",
      "Inferenz für Konfiguration Training_Runs\\MVTecAD_grid\\resnet18\\7804c936-9a41-467a-8dfc-e31f5c13998b\\STFPM_Config_resnet18.yaml abgeschlossen. \n",
      "AUROC: 0.9674185463659147, Inferenzzeit: 1.5449999000047683 Sekunden.\n",
      "Starte Inferenz für Konfiguration: Training_Runs\\MVTecAD_grid\\shufflenet_v2_x1_0\\8f25c698-9597-4255-999c-51f15eea019f\\STFPM_Config_shufflenet_v2_x1_0.yaml...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PyTorch Profiler-Analyse ---\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        70.29%        1.157s        72.01%        1.185s     395.001ms             3  \n",
      "                                  anomaly_map_inference         2.07%      33.989ms        27.70%     455.823ms     227.911ms             2  \n",
      "                                           aten::conv2d         0.06%       1.006ms        12.99%     213.730ms     962.747us           222  \n",
      "                                      aten::convolution         0.07%       1.094ms        12.93%     212.723ms     958.213us           222  \n",
      "                                     aten::_convolution         0.11%       1.843ms        12.86%     211.629ms     953.286us           222  \n",
      "                               aten::mkldnn_convolution         9.85%     162.085ms         9.91%     163.130ms     734.822us           222  \n",
      "                                            aten::copy_         4.51%      74.142ms         4.51%      74.142ms     136.792us           542  \n",
      "                                            aten::clone         0.11%       1.781ms         4.21%      69.230ms     237.088us           292  \n",
      "                                       aten::contiguous         0.03%     416.700us         4.13%      68.000ms     317.756us           214  \n",
      "                                       aten::batch_norm         0.04%     689.400us         3.89%      63.976ms     288.181us           222  \n",
      "                           aten::_batch_norm_impl_index         0.09%       1.520ms         3.85%      63.287ms     285.075us           222  \n",
      "                                aten::native_batch_norm         3.62%      59.629ms         3.73%      61.421ms     276.671us           222  \n",
      "                                              aten::cat         1.64%      27.024ms         1.70%      28.056ms     425.088us            66  \n",
      "                                             aten::relu         0.03%     470.500us         1.63%      26.769ms     183.349us           146  \n",
      "                                        aten::clamp_min         1.61%      26.458ms         1.61%      26.458ms     167.454us           158  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.646s\n",
      "\n",
      "Inference summary saved to Inference_Runs\\MVTecAD_grid\\shufflenet_v2_x1_0\\8f25c698-9597-4255-999c-51f15eea019f\\inference_summary.json\n",
      "Inferenz für Konfiguration Training_Runs\\MVTecAD_grid\\shufflenet_v2_x1_0\\8f25c698-9597-4255-999c-51f15eea019f\\STFPM_Config_shufflenet_v2_x1_0.yaml abgeschlossen. \n",
      "AUROC: 0.797827903091061, Inferenzzeit: 0.4559153000009246 Sekunden.\n",
      "\n",
      "--- Alle Inferenzläufe abgeschlossen. ---\n"
     ]
    }
   ],
   "source": [
    "training_run_folder = \"Training_Runs\"\n",
    "inference_output_dir = \"Inference_Runs\"\n",
    "\n",
    "inference_model(training_run_folder, inference_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c1c54cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade FP32-Modelle für die Quantisierung...\n",
      "Bereite das Studenten-Modell für die Quantisierung vor (FX Graph Transformation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstelle den Kalibrierungs-Daten-Loader...\n",
      "Starte die Kalibrierung des Modells...\n",
      "Kalibrierung abgeschlossen.\n",
      "Konvertiere das vorbereitete Modell zum endgültigen quantisierten Modell...\n",
      "Quantisiertes Modell und Artefakte erfolgreich gespeichert unter: quantized_models\\MVTecAD_grid\\resnet18\\7804c936-9a41-467a-8dfc-e31f5c13998b\n",
      "Lade FP32-Modelle für die Quantisierung...\n",
      "Bereite das Studenten-Modell für die Quantisierung vor (FX Graph Transformation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstelle den Kalibrierungs-Daten-Loader...\n",
      "Starte die Kalibrierung des Modells...\n",
      "Kalibrierung abgeschlossen.\n",
      "Konvertiere das vorbereitete Modell zum endgültigen quantisierten Modell...\n",
      "Quantisiertes Modell und Artefakte erfolgreich gespeichert unter: quantized_models\\MVTecAD_grid\\shufflenet_v2_x1_0\\8f25c698-9597-4255-999c-51f15eea019f\n"
     ]
    }
   ],
   "source": [
    "base_path = \"Training_runs\"\n",
    "\n",
    "config_paths_all = glob.glob(os.path.join(\n",
    "    base_path, \"**\", \"*.yaml\"), recursive=True)\n",
    "summary_metrics_paths_all = glob.glob(os.path.join(\n",
    "    base_path, \"**\", \"summary_metrics.json\"), recursive=True)\n",
    "best_student_weight_paths_all = glob.glob(os.path.join(\n",
    "    base_path, \"**\", \"*best_student.pth\"), recursive=True)\n",
    "\n",
    "for configs, summary_metrics, best_student_weights in zip(config_paths_all, summary_metrics_paths_all, best_student_weight_paths_all):\n",
    "    config = load_config(configs)\n",
    "    summary_metric = load_json(summary_metrics)\n",
    "    quantize_model(best_student_weights, config, summary_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef59b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Führe Inferenz für 2 quantisierte Modelle aus...\n",
      "Modell aus resnet18 wird verwendet...\n",
      "Lade Modelle fuer die Quantisierung...\n",
      "Bereite das Studenten-Modell fuer die Quantisierung vor...\n",
      "Konvertiere das vorbereitete Modell in ein quantisiertes Modell...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_2064\\2664680756.py:51: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  prepared_model = quantize_fx.prepare_fx(\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_2064\\2664680756.py:55: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized_model_shell = quantize_fx.convert_fx(prepared_model)\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:1343: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade die quantisierten Gewichte in das Modell...\n",
      "Lade den gesamten Test-Datensatz in den Arbeitsspeicher...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 61.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Inferenz für Konfiguration: quantized_models\\MVTecAD_grid\\resnet18\\7804c936-9a41-467a-8dfc-e31f5c13998b\\STFPM_Config_resnet18.yaml...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PyTorch Profiler-Analyse ---\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  anomaly_map_inference         1.90%      24.412ms        98.93%        1.272s     635.996ms             2  \n",
      "                                           aten::conv2d         0.02%     206.100us        48.02%     617.452ms      15.436ms            40  \n",
      "                                      aten::convolution         0.02%     285.200us        48.01%     617.246ms      15.431ms            40  \n",
      "                                     aten::_convolution         0.03%     403.800us        47.98%     616.961ms      15.424ms            40  \n",
      "                               aten::mkldnn_convolution        47.93%     616.260ms        47.95%     616.557ms      15.414ms            40  \n",
      "                                      quantized::conv2d        15.16%     194.975ms        15.19%     195.309ms       8.878ms            22  \n",
      "                                 quantized::conv2d_relu        11.14%     143.194ms        11.15%     143.375ms       8.961ms            16  \n",
      "                                       aten::batch_norm         0.01%     160.900us         5.02%      64.593ms       1.615ms            40  \n",
      "                           aten::_batch_norm_impl_index         0.03%     395.500us         5.01%      64.432ms       1.611ms            40  \n",
      "                                aten::native_batch_norm         4.93%      63.331ms         4.97%      63.937ms       1.598ms            40  \n",
      "                                        aten::clamp_min         4.48%      57.573ms         4.48%      57.573ms       1.151ms            50  \n",
      "                                             aten::relu         0.03%     345.300us         4.47%      57.443ms       1.689ms            34  \n",
      "                              aten::upsample_bilinear2d         2.07%      26.620ms         2.08%      26.683ms       3.335ms             8  \n",
      "                                       aten::max_pool2d         0.00%      25.300us         1.79%      23.018ms      11.509ms             2  \n",
      "                          aten::max_pool2d_with_indices         1.79%      22.993ms         1.79%      22.993ms      11.496ms             2  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.286s\n",
      "\n",
      "Inference summary saved to quantized_inference_results\\MVTecAD_grid\\resnet18\\7804c936-9a41-467a-8dfc-e31f5c13998b\\inference_summary.json\n",
      "Inferenz abgeschlossen. AUROC: 0.9916, Zeit: 1.2721s.\n",
      "Modell aus shufflenet_v2_x1_0 wird verwendet...\n",
      "Lade Modelle fuer die Quantisierung...\n",
      "Bereite das Studenten-Modell fuer die Quantisierung vor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_2064\\2664680756.py:51: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  prepared_model = quantize_fx.prepare_fx(\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konvertiere das vorbereitete Modell in ein quantisiertes Modell...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alant\\AppData\\Local\\Temp\\ipykernel_2064\\2664680756.py:55: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized_model_shell = quantize_fx.convert_fx(prepared_model)\n",
      "c:\\Users\\alant\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:1343: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade die quantisierten Gewichte in das Modell...\n",
      "Lade den gesamten Test-Datensatz in den Arbeitsspeicher...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 70.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Inferenz für Konfiguration: quantized_models\\MVTecAD_grid\\shufflenet_v2_x1_0\\8f25c698-9597-4255-999c-51f15eea019f\\STFPM_Config_shufflenet_v2_x1_0.yaml...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PyTorch Profiler-Analyse ---\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  anomaly_map_inference         5.01%      58.146ms        98.83%        1.146s     573.128ms             2  \n",
      "                                      quantized::conv2d        60.61%     702.937ms        60.98%     707.214ms      18.611ms            38  \n",
      "                                           aten::conv2d         0.04%     433.000us        10.08%     116.893ms       1.044ms           112  \n",
      "                                      aten::convolution         0.07%     790.000us        10.04%     116.459ms       1.040ms           112  \n",
      "                                     aten::_convolution         0.11%       1.235ms         9.97%     115.670ms       1.033ms           112  \n",
      "                               aten::mkldnn_convolution         7.94%      92.034ms         7.98%      92.598ms     826.765us           112  \n",
      "                                       aten::contiguous         0.03%     366.800us         5.42%      62.887ms     338.102us           186  \n",
      "                                            aten::clone         1.99%      23.110ms         5.39%      62.520ms     336.130us           186  \n",
      "                                              aten::cat         2.68%      31.035ms         5.15%      59.778ms     649.764us            92  \n",
      "                                 quantized::conv2d_relu         3.33%      38.597ms         4.64%      53.826ms     768.940us            70  \n",
      "                                            aten::copy_         3.89%      45.163ms         3.89%      45.163ms     342.144us           132  \n",
      "                                       aten::batch_norm         0.05%     538.600us         3.32%      38.488ms     343.639us           112  \n",
      "                           aten::_batch_norm_impl_index         0.07%     806.400us         3.27%      37.949ms     338.830us           112  \n",
      "                                aten::native_batch_norm         3.09%      35.877ms         3.19%      36.967ms     330.060us           112  \n",
      "                               aten::linalg_vector_norm         1.92%      22.228ms         1.92%      22.228ms       1.852ms            12  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.160s\n",
      "\n",
      "Inference summary saved to quantized_inference_results\\MVTecAD_grid\\shufflenet_v2_x1_0\\8f25c698-9597-4255-999c-51f15eea019f\\inference_summary.json\n",
      "Inferenz abgeschlossen. AUROC: 0.6424, Zeit: 1.1463s.\n",
      "\n",
      "--- Alle Inferenzläufe abgeschlossen. ---\n"
     ]
    }
   ],
   "source": [
    "inference_output_dir = 'quantized_inference_results'\n",
    "device = torch.device('cpu')\n",
    "\n",
    "quantized_weights_paths = glob.glob(os.path.join(\n",
    "    'quantized_models', '**', 'quantized_model.pth'), recursive=True)\n",
    "\n",
    "print(\n",
    "    f\"Führe Inferenz für {len(quantized_weights_paths)} quantisierte Modelle aus...\")\n",
    "\n",
    "for weight_path in quantized_weights_paths:\n",
    "    dir_path = os.path.dirname(weight_path)\n",
    "    model_name = Path(weight_path).parent.parent.name\n",
    "    print(f\"Modell aus {model_name} wird verwendet...\")\n",
    "\n",
    "    yaml_filename = None\n",
    "    for file in os.listdir(dir_path):\n",
    "        if file.endswith('.yaml'):\n",
    "            yaml_filename = file\n",
    "            break\n",
    "\n",
    "    if yaml_filename is None:\n",
    "        print(\n",
    "            f\"Keine YAML-Konfigurationsdatei im Verzeichnis {dir_path} gefunden.\")\n",
    "        continue\n",
    "\n",
    "    json_path = os.path.join(dir_path, 'summary_metric.json')\n",
    "    yaml_path = os.path.join(dir_path, yaml_filename)\n",
    "\n",
    "    if not os.path.exists(json_path):\n",
    "        print(\n",
    "            f\"Keine JSON-Zusammenfassungsdatei im Verzeichnis {dir_path} gefunden.\")\n",
    "        continue\n",
    "\n",
    "    config = load_config(yaml_path)\n",
    "    summary_data = load_json(json_path)\n",
    "    training_id = summary_data.get('training_id', 'quantized_run')\n",
    "    print(\"Lade Modelle fuer die Quantisierung...\")\n",
    "    inference_model = STFPM_QuantizedModels(\n",
    "        architecture=config['model']['architecture'],\n",
    "        layers=config['model']['layers'],\n",
    "        quantize=False\n",
    "    ).to(device).eval()\n",
    "\n",
    "    stem_model = inference_model.stem_model.eval()\n",
    "    student_model = inference_model.student_model.eval()\n",
    "    qconfig_mapping = get_default_qconfig_mapping('fbgemm')\n",
    "    example_inputs = (stem_model(torch.randn(\n",
    "        1, 3, config['dataset']['img_size'], config['dataset']['img_size']\n",
    "    )),)\n",
    "    print(\"Bereite das Studenten-Modell fuer die Quantisierung vor...\")\n",
    "    prepared_model = quantize_fx.prepare_fx(\n",
    "        student_model, qconfig_mapping, example_inputs\n",
    "    )\n",
    "    print(\"Konvertiere das vorbereitete Modell in ein quantisiertes Modell...\")\n",
    "    quantized_model_shell = quantize_fx.convert_fx(prepared_model)\n",
    "    print(\"Lade die quantisierten Gewichte in das Modell...\")\n",
    "    state_dict = torch.load(weight_path, map_location=device)\n",
    "    quantized_model_shell.load_state_dict(state_dict)\n",
    "\n",
    "    inference_model.student_model = quantized_model_shell.eval()\n",
    "\n",
    "    try:\n",
    "        test_set = MVTecDataset(\n",
    "            img_size=config['dataset']['img_size'],\n",
    "            base_path=config['dataset']['base_path'],\n",
    "            cls=config['dataset']['class'],\n",
    "            mode='test',\n",
    "            download_if_missing=False\n",
    "        )\n",
    "        print(\"Lade den gesamten Test-Datensatz in den Arbeitsspeicher...\")\n",
    "        memory_cache = [test_set[i] for i in tqdm(range(len(test_set)))]\n",
    "        test_loader = DataLoader(\n",
    "            memory_cache,\n",
    "            batch_size=config['dataloader']['batch_size'],\n",
    "            shuffle=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Laden des Test-Datensatzes für {yaml_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    infer = Inference(\n",
    "        model=inference_model,\n",
    "        test_loader=test_loader,\n",
    "        config=config,\n",
    "        output_dir=inference_output_dir,\n",
    "        path_to_student_weight=None,\n",
    "        trainings_id=training_id,\n",
    "        inferenz=True\n",
    "    )\n",
    "\n",
    "    print(f\"Starte Inferenz für Konfiguration: {yaml_path}...\")\n",
    "    auroc_score, total_inference_time = infer.evaluate_quantized_loaded_model()\n",
    "    infer.create_inference_summary(\n",
    "        summary_data, auroc_score, total_inference_time)\n",
    "    print(\n",
    "        f\"Inferenz abgeschlossen. AUROC: {auroc_score:.4f}, Zeit: {total_inference_time:.4f}s.\")\n",
    "\n",
    "    # infer.generate_heatmaps_from_saved_maps()\n",
    "\n",
    "print(\"\\n--- Alle Inferenzläufe abgeschlossen. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcf5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\n",
    "    r'Configs\\shufflenet_v2_x1_0\\grid\\STFPM_Config_shufflenet_v2_x1_0_grid.yaml')\n",
    "model = STFPM_QuantizedModels(\n",
    "    architecture=config['model']['architecture'],\n",
    "    layers=config['model']['layers'],\n",
    "    quantize=True\n",
    ")\n",
    "print(model.teacher_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844108c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(inference_model.student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b66448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import time  # Hinzugefügt: Modul für die Zeitmessung\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. ONNX-Modell laden\n",
    "onnx_model_path = r\"onnx_models\\STFPM_bottle_mobilenetv4_conv_large.onnx\"\n",
    "sess = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "image_path = glob.glob(os.path.join(\n",
    "    r'Images\\bottle\\test\\broken_large', '*.png'))\n",
    "for path in image_path:\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "    img_size = 256\n",
    "    image = image.resize((img_size, img_size))\n",
    "\n",
    "    input_data = np.array(image, dtype=np.uint8)\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    outputs = sess.run(None, {input_name: input_data})\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    inference_time = end_time - start_time\n",
    "\n",
    "    anomaly_map = outputs[0]\n",
    "    anomaly_score = outputs[1]\n",
    "\n",
    "    print(f\"Anomalie-Score für das Bild: {anomaly_score[0]}\")\n",
    "    print(f\"Inferenzzeit: {inference_time:.4f} Sekunden\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # 2. Originalbild anzeigen\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"Originalbild\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # 3. Heatmap über das Originalbild legen\n",
    "    axes[1].imshow(image)\n",
    "    heatmap = axes[1].imshow(np.squeeze(anomaly_map), cmap='jet', alpha=0.5)\n",
    "    axes[1].set_title(\"Anomalie-Heatmap\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # 4. Farbbalken für die Heatmap hinzufügen\n",
    "    fig.colorbar(heatmap, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    # 5. Plot anzeigen oder speichern\n",
    "    plt.suptitle(\"Vergleich: Originalbild vs. Anomalie-Heatmap\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
